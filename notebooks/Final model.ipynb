{"cells":[{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n\n\nfrom itertools import product\nfrom tqdm import tqdm\nimport calendar\nfrom catboost import CatBoostRegressor\nimport lightgbm as lgb\nfrom sklearn.preprocessing import LabelEncoder\n\ntest = pd.read_csv('../input/competitive-data-science-predict-future-sales/test.csv')\nsales = pd.read_csv('../input/competitive-data-science-predict-future-sales/sales_train.csv')\nshops = pd.read_csv('../input/competitive-data-science-predict-future-sales/shops.csv')\nitems = pd.read_csv('../input/competitive-data-science-predict-future-sales/items.csv')\n# item_cats = pd.read_csv('../input/competitive-data-science-predict-future-sales/item_categories.csv')\n\nshops['city'] = shops['shop_name'].apply(lambda x: x.split()[0].lower())\nshops['city_id'] = LabelEncoder().fit_transform(shops['city'])\n\nsales['item_category_id'] = sales.item_id.map(items.item_category_id)\nsales.item_cnt_day = sales.item_cnt_day.clip(0, 20)\n# sales = sales[sales.item_price < 30000]\nsales['city_id'] = sales.shop_id.map(shops.city_id)\n\nindex_cols = ['date_block_num', 'shop_id', 'item_id']\n\ntrain = []\n# block = sales.date_block_num.unique()\n\nfor block in tqdm(sales.date_block_num.unique()):\n    cur_items = sales.loc[sales.date_block_num == block, 'item_id'].unique()\n    cur_shops = sales.loc[sales.date_block_num == block, 'shop_id'].unique()\n    train.append(\n        np.array(list(\n            product(*[[block], cur_shops, cur_items])\n        ))\n    )\n    \ntrain = pd.DataFrame(np.vstack(train), columns=index_cols, dtype=np.int32)\n\n\n# In[ ]:\n\n\ntest['date_block_num'] = np.full(test.shape[0], 34)\n\n\n# In[ ]:\n\n\ngroup = sales.groupby(index_cols).agg({'item_cnt_day': 'sum'})\ngroup.columns = ['item_cnt_month']\ngroup.reset_index(inplace= True)\ntrain = pd.merge(train, group, on= index_cols, how= 'left')\ntrain.item_cnt_month = train.item_cnt_month.fillna(0).clip(0, 20)\n\n\nlength_train = train.shape[0]\n\n\n# In[ ]:\n\n\ntrain = train.append(test.drop(columns=['ID']), ignore_index=True)\n\n\nprint ('data created')\nprint ('feature creation starting')\n\n\ny = train.item_cnt_month[:length_train]\n\ndef num_days(block):\n    y = int(2013 + block/12)\n    m = 1 + block % 12\n    return max(calendar.monthcalendar(y, m)[-1])\n\ndef wday(block, d):\n    y = int(2013 + block/12)\n    m = 1 + block % 12\n    cal = calendar.monthcalendar(y, m)\n    return sum([1 for w in cal if w[d]])\n\n\n# In[ ]:\n\n\ndef lag_feature(df, lags, col='item_cnt_month'):\n    tmp = df[['date_block_num','shop_id','item_id',col]]\n    for i in tqdm(lags):\n        name = col+'_lag_'+str(i)\n        shifted = tmp.copy()\n        shifted.columns = ['date_block_num','shop_id','item_id', name]\n        shifted['date_block_num'] += i\n        df = pd.merge(df, shifted, on=['date_block_num','shop_id','item_id'], how='left')\n        df[name] = df[name].astype('float16')\n    return df\n\n\n# In[ ]:\n\n\ndef add(train, index_cols, name, col='item_cnt_month', func='mean'):\n    group = train[train.date_block_num.isin(sales.date_block_num.unique())].groupby(index_cols).agg({col: func})\n    group.columns = [name]\n    group.reset_index(inplace= True)\n    train = pd.merge(train, group, on= index_cols, how= 'left')\n    train[name] = train[name].fillna(0).astype('float16')\n    return train\n\n\n# In[ ]:\n\n\ntrain['year'] = (train.date_block_num/12 + 2013).astype(int).astype('int32')\ntrain['month'] = (train.date_block_num % 12 + 1).astype(int).astype('int32')\n\nsales['month'] = (sales.date_block_num % 12 + 1).astype(int).astype('int32')\n\n\n# In[ ]:\n\n\ntrain['num_days'] = train.date_block_num.map(pd.Series([num_days(i) for i in range(40)])).astype('int32')\n\ntrain['num_sat'] = train.date_block_num.map(pd.Series([wday(i, 5) for i in range(40)])).astype('int32')\n# for d, wk in enumerate(['mon', 'tue', 'wed', 'thur', 'fri', 'sat', 'sun']):\n#     train['num_'+ wk] = train.date_block_num.map(pd.Series([wday(i, d) for i in range(40)]))\n\n\n# In[ ]:\n\n\nprices       = sales.groupby('item_id' ).item_price.mean()\nprices_month = sales.groupby('month'   ).item_price.mean()\nprices_shop  = sales.groupby('shop_id' ).item_price.mean()\n\ntrain['item_category_id'] = train.item_id.map(items.item_category_id).astype('int32')\ntrain['price'] = train.item_id.map(prices).astype('float16')\ntrain['price_month'] = train.month.map(prices_month).astype('float16')\ntrain['price_shop'] = train.shop_id.map(prices_shop).astype('float16')\ntrain['city_id'] = train.shop_id.map(shops.city_id)\n\n\nprint ('target encoding started')\n\n# In[ ]:\n\n\n# [train.date_block_num.isin(sales.date_block_num.unique())]\nblock_sales = sales.date_block_num.unique()\n\ncount_month = train[:length_train].groupby('month'  ).item_cnt_month.mean()\ncount_shop  = train[:length_train].groupby('shop_id').item_cnt_month.mean()\ncount_item  = train[:length_train].groupby('item_id').item_cnt_month.mean()\n\ntrain['cnt_month'] = train.month.map(count_month).astype('float16')\ntrain['cnt_shop'] = train.shop_id.map(count_shop).astype('float16')\ntrain['cnt_item'] = train.item_id.map(count_item).astype('float16')\n\n\n# In[ ]:\n\n\n# train = add(train, ['date_block_num', 'item_id'], 'avg_cnt_month-item')\ntrain = add(train, ['date_block_num', 'shop_id'], 'avg_cnt_month-shop')\ntrain = add(train, ['item_id', 'shop_id'], 'avg_cnt_item-shop')\ntrain = add(train, ['item_id', 'city_id'], 'avg_cnt_item-city')\n\ntrain = add(train, ['date_block_num', 'item_id'], 'avg_cnt_month-item')\n# train = add(train, ['month', 'item_id'], 'avg_cnt_month')\n\n\n# In[ ]:\n\n\n## lag\n\nprint ('lag feature creation starting')\n\nlag_features = [\n    'item_cnt_month', \n    'cnt_shop', \n    'cnt_month', \n    'cnt_item', \n    'avg_cnt_month-item', \n    'avg_cnt_month-shop', \n    'avg_cnt_item-shop', \n    'avg_cnt_item-city',\n    'price', \n    'price_month', \n    'price_shop', \n#     'avg_cnt_month'\n]\n\n\nfor col in lag_features:\n    train = lag_feature(train, [1, 2, 3, 12], col)\n    print (col)\n\n\ndf = train.drop(columns= lag_features[1:])\ndf = df[df.date_block_num > 2]\n# df.fillna(0, inplace= True)\n\nX_train = df[df.date_block_num < 33].drop('item_cnt_month', axis=1)\nx_val   = df[df.date_block_num ==33].drop('item_cnt_month', axis=1)\ntest    = df[df.date_block_num ==34].drop('item_cnt_month', axis=1)\n\ny     = df[df.date_block_num < 33].item_cnt_month\ny_val = df[df.date_block_num ==33].item_cnt_month\n\nloc = './'\n\nprint ('model creation starting')\n\n\ncategory_columns = ['shop_id', 'item_id', 'year', 'month', 'item_category_id', 'city_id']\n\n# model = CatBoostRegressor(2000, early_stopping_rounds=300, \n#                           learning_rate= 0.1, \n#                           random_seed=1, \n#                           task_type= 'GPU', \n#                           cat_features=category_columns)\n\n# print ('model fitting starting')\n\n# model.fit(X_train, y, cat_features= category_columns, eval_set=(x_val, y_val), verbose= 40, \n#           save_snapshot= True, snapshot_file= loc+'cat_3_snapshot4.snap', snapshot_interval= 120)\n# model.save_model(loc + 'cat_3.cbm')\n\n\nfeature_name = X_train.columns.tolist()\n\nparams = {\n    'objective': 'mse',\n    'metric': 'rmse',\n    'num_leaves': 2 ** 7 - 1,\n    'learning_rate': 0.005,\n    'feature_fraction': 0.75,\n    'bagging_fraction': 0.75,\n    'bagging_freq': 5,\n    'seed': 1,\n    'verbose': 1\n}\n\nlgb_train = lgb.Dataset(X_train[feature_name], y)\nlgb_eval = lgb.Dataset(x_val[feature_name], y_val, reference=lgb_train)\n\nevals_result = {}\nmodel = lgb.train(\n        params, \n        lgb_train,\n        num_boost_round=3000,\n        valid_sets=(lgb_train, lgb_eval), \n        feature_name = feature_name,\n        categorical_feature = category_columns,\n        verbose_eval=5, \n        evals_result = evals_result,\n        early_stopping_rounds = 100\n)\n\n\n\nsub = pd.DataFrame({\n    'ID': np.arange(0, test.shape[0]), \n    'item_cnt_month' : model.predict(test)\n})\nsub.item_cnt_month = sub.item_cnt_month.clip(0, 20)\nsub[['ID', 'item_cnt_month']].to_csv(loc + 'sub_cat_5.csv', index=False)\n\npraint ('Done')","execution_count":null,"outputs":[{"output_type":"stream","text":"/kaggle/input/competitive-data-science-predict-future-sales/items.csv\n/kaggle/input/competitive-data-science-predict-future-sales/sales_train.csv\n/kaggle/input/competitive-data-science-predict-future-sales/item_categories.csv\n/kaggle/input/competitive-data-science-predict-future-sales/test.csv\n/kaggle/input/competitive-data-science-predict-future-sales/shops.csv\n/kaggle/input/competitive-data-science-predict-future-sales/sample_submission.csv\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 34/34 [00:12<00:00,  2.62it/s]\n","name":"stderr"},{"output_type":"stream","text":"data created\nfeature creation starting\ntarget encoding started\nlag feature creation starting\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 4/4 [00:29<00:00,  7.33s/it]\n100%|██████████| 4/4 [00:29<00:00,  7.28s/it]\n100%|██████████| 4/4 [00:30<00:00,  7.53s/it]\n100%|██████████| 4/4 [00:30<00:00,  7.72s/it]\n100%|██████████| 4/4 [00:31<00:00,  7.95s/it]\n100%|██████████| 4/4 [00:32<00:00,  8.17s/it]\n100%|██████████| 4/4 [00:33<00:00,  8.44s/it]\n100%|██████████| 4/4 [00:34<00:00,  8.62s/it]\n100%|██████████| 4/4 [00:35<00:00,  8.79s/it]\n100%|██████████| 4/4 [00:35<00:00,  9.00s/it]\n100%|██████████| 4/4 [00:36<00:00,  9.14s/it]\n","name":"stderr"},{"output_type":"stream","text":"model creation starting\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1295: UserWarning: categorical_feature in Dataset is overridden.\nNew categorical_feature is ['city_id', 'item_category_id', 'item_id', 'month', 'shop_id', 'year']\n  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n","name":"stderr"},{"output_type":"stream","text":"Training until validation scores don't improve for 100 rounds\n[5]\ttraining's rmse: 1.19743\tvalid_1's rmse: 1.12627\n[10]\ttraining's rmse: 1.18161\tvalid_1's rmse: 1.11495\n[15]\ttraining's rmse: 1.166\tvalid_1's rmse: 1.10473\n[20]\ttraining's rmse: 1.15122\tvalid_1's rmse: 1.09429\n[25]\ttraining's rmse: 1.13703\tvalid_1's rmse: 1.08433\n[30]\ttraining's rmse: 1.12359\tvalid_1's rmse: 1.07589\n[35]\ttraining's rmse: 1.11032\tvalid_1's rmse: 1.0677\n[40]\ttraining's rmse: 1.09718\tvalid_1's rmse: 1.06002\n[45]\ttraining's rmse: 1.08413\tvalid_1's rmse: 1.05249\n[50]\ttraining's rmse: 1.07242\tvalid_1's rmse: 1.04481\n[55]\ttraining's rmse: 1.06067\tvalid_1's rmse: 1.0378\n[60]\ttraining's rmse: 1.04875\tvalid_1's rmse: 1.03131\n[65]\ttraining's rmse: 1.0381\tvalid_1's rmse: 1.02474\n[70]\ttraining's rmse: 1.02756\tvalid_1's rmse: 1.01884\n[75]\ttraining's rmse: 1.01704\tvalid_1's rmse: 1.013\n[80]\ttraining's rmse: 1.00724\tvalid_1's rmse: 1.00715\n[85]\ttraining's rmse: 0.997525\tvalid_1's rmse: 1.00246\n[90]\ttraining's rmse: 0.987746\tvalid_1's rmse: 0.997891\n[95]\ttraining's rmse: 0.978885\tvalid_1's rmse: 0.993244\n[100]\ttraining's rmse: 0.9702\tvalid_1's rmse: 0.989108\n[105]\ttraining's rmse: 0.961569\tvalid_1's rmse: 0.985421\n[110]\ttraining's rmse: 0.953728\tvalid_1's rmse: 0.981587\n[115]\ttraining's rmse: 0.945931\tvalid_1's rmse: 0.977827\n[120]\ttraining's rmse: 0.938123\tvalid_1's rmse: 0.974532\n[125]\ttraining's rmse: 0.930608\tvalid_1's rmse: 0.971469\n[130]\ttraining's rmse: 0.923056\tvalid_1's rmse: 0.968941\n[135]\ttraining's rmse: 0.915783\tvalid_1's rmse: 0.966493\n[140]\ttraining's rmse: 0.908871\tvalid_1's rmse: 0.963831\n[145]\ttraining's rmse: 0.902647\tvalid_1's rmse: 0.96087\n[150]\ttraining's rmse: 0.896019\tvalid_1's rmse: 0.958854\n[155]\ttraining's rmse: 0.889568\tvalid_1's rmse: 0.956787\n[160]\ttraining's rmse: 0.883446\tvalid_1's rmse: 0.954899\n[165]\ttraining's rmse: 0.877764\tvalid_1's rmse: 0.952561\n[170]\ttraining's rmse: 0.871802\tvalid_1's rmse: 0.950823\n[175]\ttraining's rmse: 0.866584\tvalid_1's rmse: 0.948799\n[180]\ttraining's rmse: 0.861354\tvalid_1's rmse: 0.947308\n[185]\ttraining's rmse: 0.85624\tvalid_1's rmse: 0.945915\n[190]\ttraining's rmse: 0.851443\tvalid_1's rmse: 0.944343\n[195]\ttraining's rmse: 0.847333\tvalid_1's rmse: 0.942663\n[200]\ttraining's rmse: 0.842416\tvalid_1's rmse: 0.941727\n[205]\ttraining's rmse: 0.83774\tvalid_1's rmse: 0.940871\n[210]\ttraining's rmse: 0.833254\tvalid_1's rmse: 0.939813\n[215]\ttraining's rmse: 0.829245\tvalid_1's rmse: 0.9383\n[220]\ttraining's rmse: 0.825192\tvalid_1's rmse: 0.937227\n[225]\ttraining's rmse: 0.821158\tvalid_1's rmse: 0.936184\n[230]\ttraining's rmse: 0.817275\tvalid_1's rmse: 0.935565\n[235]\ttraining's rmse: 0.813798\tvalid_1's rmse: 0.934396\n[240]\ttraining's rmse: 0.810362\tvalid_1's rmse: 0.93356\n[245]\ttraining's rmse: 0.806862\tvalid_1's rmse: 0.932976\n[250]\ttraining's rmse: 0.803668\tvalid_1's rmse: 0.932031\n[255]\ttraining's rmse: 0.800253\tvalid_1's rmse: 0.931606\n[260]\ttraining's rmse: 0.796848\tvalid_1's rmse: 0.930977\n[265]\ttraining's rmse: 0.793642\tvalid_1's rmse: 0.930638\n","name":"stdout"}]}],"metadata":{"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat":4,"nbformat_minor":4}