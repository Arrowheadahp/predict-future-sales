{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": false,
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/competitive-data-science-predict-future-sales/items.csv\n",
      "/kaggle/input/competitive-data-science-predict-future-sales/shops.csv\n",
      "/kaggle/input/competitive-data-science-predict-future-sales/sales_train.csv\n",
      "/kaggle/input/competitive-data-science-predict-future-sales/test.csv\n",
      "/kaggle/input/competitive-data-science-predict-future-sales/sample_submission.csv\n",
      "/kaggle/input/competitive-data-science-predict-future-sales/item_categories.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:13<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data created\n",
      "feature creation starting\n",
      "target encoding started\n",
      "lag feature creation starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:39<00:00,  9.83s/it]\n",
      "100%|██████████| 4/4 [00:33<00:00,  8.41s/it]\n",
      "100%|██████████| 4/4 [00:34<00:00,  8.70s/it]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['cnt_item'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f770db36a5df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlag_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlag_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-f770db36a5df>\u001b[0m in \u001b[0;36mlag_feature\u001b[0;34m(df, lags, col)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlag_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'item_cnt_month'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date_block_num'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'shop_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'item_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_lag_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2906\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2907\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2908\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2910\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1302\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m             \u001b[0;31m# we skip the warning on Categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['cnt_item'] not in index\""
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "import calendar\n",
    "from catboost import CatBoostRegressor\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "test = pd.read_csv('../input/competitive-data-science-predict-future-sales/test.csv')\n",
    "sales = pd.read_csv('../input/competitive-data-science-predict-future-sales/sales_train.csv')\n",
    "shops = pd.read_csv('../input/competitive-data-science-predict-future-sales/shops.csv')\n",
    "items = pd.read_csv('../input/competitive-data-science-predict-future-sales/items.csv')\n",
    "# item_cats = pd.read_csv('../input/competitive-data-science-predict-future-sales/item_categories.csv')\n",
    "\n",
    "shops['city'] = shops['shop_name'].apply(lambda x: x.split()[0].lower())\n",
    "shops['city_id'] = LabelEncoder().fit_transform(shops['city'])\n",
    "\n",
    "sales['item_category_id'] = sales.item_id.map(items.item_category_id)\n",
    "sales.item_cnt_day = sales.item_cnt_day.clip(0, 20)\n",
    "# sales = sales[sales.item_price < 30000]\n",
    "sales['city_id'] = sales.shop_id.map(shops.city_id)\n",
    "\n",
    "index_cols = ['date_block_num', 'shop_id', 'item_id']\n",
    "\n",
    "train = []\n",
    "# block = sales.date_block_num.unique()\n",
    "\n",
    "for block in tqdm(sales.date_block_num.unique()):\n",
    "    cur_items = sales.loc[sales.date_block_num == block, 'item_id'].unique()\n",
    "    cur_shops = sales.loc[sales.date_block_num == block, 'shop_id'].unique()\n",
    "    train.append(\n",
    "        np.array(list(\n",
    "            product(*[[block], cur_shops, cur_items])\n",
    "        ))\n",
    "    )\n",
    "    \n",
    "train = pd.DataFrame(np.vstack(train), columns=index_cols, dtype=np.int32)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "test['date_block_num'] = np.full(test.shape[0], 34)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "group = sales.groupby(index_cols).agg({'item_cnt_day': 'sum'})\n",
    "group.columns = ['item_cnt_month']\n",
    "group.reset_index(inplace= True)\n",
    "train = pd.merge(train, group, on= index_cols, how= 'left')\n",
    "train.item_cnt_month = train.item_cnt_month.fillna(0).clip(0, 20)\n",
    "\n",
    "\n",
    "length_train = train.shape[0]\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "train = train.append(test.drop(columns=['ID']), ignore_index=True)\n",
    "\n",
    "\n",
    "print ('data created')\n",
    "print ('feature creation starting')\n",
    "\n",
    "\n",
    "y = train.item_cnt_month[:length_train]\n",
    "\n",
    "def num_days(block):\n",
    "    y = int(2013 + block/12)\n",
    "    m = 1 + block % 12\n",
    "    return max(calendar.monthcalendar(y, m)[-1])\n",
    "\n",
    "def wday(block, d):\n",
    "    y = int(2013 + block/12)\n",
    "    m = 1 + block % 12\n",
    "    cal = calendar.monthcalendar(y, m)\n",
    "    return sum([1 for w in cal if w[d]])\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def lag_feature(df, lags, col='item_cnt_month'):\n",
    "    tmp = df[['date_block_num','shop_id','item_id',col]]\n",
    "    for i in tqdm(lags):\n",
    "        name = col+'_lag_'+str(i)\n",
    "        shifted = tmp.copy()\n",
    "        shifted.columns = ['date_block_num','shop_id','item_id', name]\n",
    "        shifted['date_block_num'] += i\n",
    "        df = pd.merge(df, shifted, on=['date_block_num','shop_id','item_id'], how='left')\n",
    "        df[name] = df[name].astype('float16')\n",
    "    return df\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def add(train, index_cols, name, col='item_cnt_month', func='mean'):\n",
    "    group = train[train.date_block_num.isin(sales.date_block_num.unique())].groupby(index_cols).agg({col: func})\n",
    "    group.columns = [name]\n",
    "    group.reset_index(inplace= True)\n",
    "    train = pd.merge(train, group, on= index_cols, how= 'left')\n",
    "    train[name] = train[name].fillna(0).astype('float16')\n",
    "    return train\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "train['year'] = (train.date_block_num/12 + 2013).astype(int).astype('int32')\n",
    "train['month'] = (train.date_block_num % 12 + 1).astype(int).astype('int32')\n",
    "\n",
    "sales['month'] = (sales.date_block_num % 12 + 1).astype(int).astype('int32')\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "train['num_days'] = train.date_block_num.map(pd.Series([num_days(i) for i in range(40)])).astype('int32')\n",
    "\n",
    "train['num_sat'] = train.date_block_num.map(pd.Series([wday(i, 5) for i in range(40)])).astype('int32')\n",
    "# for d, wk in enumerate(['mon', 'tue', 'wed', 'thur', 'fri', 'sat', 'sun']):\n",
    "#     train['num_'+ wk] = train.date_block_num.map(pd.Series([wday(i, d) for i in range(40)]))\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "prices       = sales.groupby('item_id' ).item_price.mean()\n",
    "prices_month = sales.groupby('month'   ).item_price.mean()\n",
    "prices_shop  = sales.groupby('shop_id' ).item_price.mean()\n",
    "\n",
    "train['item_category_id'] = train.item_id.map(items.item_category_id).astype('int32')\n",
    "train['price'] = train.item_id.map(prices).astype('float16')\n",
    "train['price_month'] = train.month.map(prices_month).astype('float16')\n",
    "train['price_shop'] = train.shop_id.map(prices_shop).astype('float16')\n",
    "train['city_id'] = train.shop_id.map(shops.city_id)\n",
    "\n",
    "\n",
    "print ('target encoding started')\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# [train.date_block_num.isin(sales.date_block_num.unique())]\n",
    "block_sales = sales.date_block_num.unique()\n",
    "\n",
    "count_month = train[:length_train].groupby('month'  ).item_cnt_month.mean()\n",
    "count_shop  = train[:length_train].groupby('shop_id').item_cnt_month.mean()\n",
    "count_item  = train[:length_train].groupby('item_id').item_cnt_month.mean()\n",
    "\n",
    "train['cnt_month'] = train.month.map(count_month).astype('float16')\n",
    "train['cnt_shop'] = train.shop_id.map(count_shop).astype('float16')\n",
    "train['cnt_item'] = train.item_id.map(count_item).astype('float16')\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# train = add(train, ['date_block_num', 'item_id'], 'avg_cnt_month-item')\n",
    "train = add(train, ['date_block_num', 'shop_id'], 'avg_cnt_month-shop')\n",
    "train = add(train, ['item_id', 'shop_id'], 'avg_cnt_item-shop')\n",
    "train = add(train, ['item_id', 'city_id'], 'avg_cnt_item-city')\n",
    "\n",
    "train = add(train, ['date_block_num', 'item_id'], 'avg_cnt_month-item')\n",
    "train = add(train, ['month', 'item_id'], 'avg_cnt_month')\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "## lag\n",
    "\n",
    "print ('lag feature creation starting')\n",
    "\n",
    "lag_features = [\n",
    "    'item_cnt_month', \n",
    "    'cnt_shop', \n",
    "    'cnt_month', \n",
    "    'cnt_item', \n",
    "    'avg_cnt_month-item', \n",
    "    'avg_cnt_month-shop', \n",
    "    'avg_cnt_item-shop', \n",
    "    'avg_cnt_item-city',\n",
    "    'price', \n",
    "    'price_month', \n",
    "    'price_shop'\n",
    "]\n",
    "\n",
    "\n",
    "for col in lag_features:\n",
    "    train = lag_feature(train, [1, 2, 3, 12], col)\n",
    "\n",
    "\n",
    "df = train.drop(columns= lag_features[1:])\n",
    "df = df[df.date_block_num > 2]\n",
    "# df.fillna(0, inplace= True)\n",
    "\n",
    "X_train = df[df.date_block_num < 33].drop('item_cnt_month', axis=1)\n",
    "x_val   = df[df.date_block_num ==33].drop('item_cnt_month', axis=1)\n",
    "test    = df[df.date_block_num ==34].drop('item_cnt_month', axis=1)\n",
    "\n",
    "y     = df[df.date_block_num < 33].item_cnt_month\n",
    "y_val = df[df.date_block_num ==33].item_cnt_month\n",
    "\n",
    "loc = './'\n",
    "\n",
    "print ('model creation starting')\n",
    "\n",
    "\n",
    "category_columns = ['shop_id', 'item_id', 'year', 'month', 'item_category_id', 'city_id']\n",
    "\n",
    "# model = CatBoostRegressor(2000, early_stopping_rounds=300, \n",
    "#                           learning_rate= 0.1, \n",
    "#                           random_seed=1, \n",
    "#                           task_type= 'GPU', \n",
    "#                           cat_features=category_columns)\n",
    "\n",
    "# print ('model fitting starting')\n",
    "\n",
    "# model.fit(X_train, y, cat_features= category_columns, eval_set=(x_val, y_val), verbose= 40, \n",
    "#           save_snapshot= True, snapshot_file= loc+'cat_3_snapshot4.snap', snapshot_interval= 120)\n",
    "# model.save_model(loc + 'cat_3.cbm')\n",
    "\n",
    "\n",
    "# feature_name = X_train.columns.tolist()\n",
    "\n",
    "# params = {\n",
    "#     'objective': 'mse',\n",
    "#     'metric': 'rmse',\n",
    "#     'num_leaves': 2 ** 7 - 1,\n",
    "#     'learning_rate': 0.005,\n",
    "#     'feature_fraction': 0.75,\n",
    "#     'bagging_fraction': 0.75,\n",
    "#     'bagging_freq': 5,\n",
    "#     'seed': 1,\n",
    "#     'verbose': 1\n",
    "# }\n",
    "\n",
    "# lgb_train = lgb.Dataset(X_train[feature_name], y)\n",
    "# lgb_eval = lgb.Dataset(x_val[feature_name], y_val, reference=lgb_train)\n",
    "\n",
    "# evals_result = {}\n",
    "# model = lgb.train(\n",
    "#         params, \n",
    "#         lgb_train,\n",
    "#         num_boost_round=1500,\n",
    "#         valid_sets=(lgb_train, lgb_eval), \n",
    "#         feature_name = feature_name,\n",
    "#         categorical_feature = category_columns,\n",
    "#         verbose_eval=5, \n",
    "#         evals_result = evals_result,\n",
    "#         early_stopping_rounds = 100\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "sub = pd.DataFrame({\n",
    "    'ID': np.arange(0, test.shape[0]), \n",
    "    'item_cnt_month' : model.predict(test)\n",
    "})\n",
    "sub.item_cnt_month = sub.item_cnt_month.clip(0, 20)\n",
    "sub[['ID', 'item_cnt_month']].to_csv(loc + 'sub_cat_5.csv', index=False)\n",
    "\n",
    "praint ('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
